training:
    desc: "episodes: episodes, batchSize: learning batch size, gamma: reward discount, epsStart: epsilon-greedy start value, epsEnd: epsilon-greedy end value, epsDecay: epsilon-greedy decay time constant, targetUpdate: episodes between target network updates, learning rate: learning rate"
    value:
        batchSize: 128
        episodes: 500
        epsDecay: 10000
        epsEnd: 0.01
        epsStart: 0.9
        gamma: 0.999
        learningRate: 0.01
        targetUpdate: 10
environment:
    desc: "name: environment name, render: whether to render environment"
    value:
        actionBounds: [0.0, 40.0]
        actions: [0.0, 30.0]
        altBounds: [8.0, 12.0]
        delay: 0
        goalObs: [0.0]
        gravity: 9.81
        initRand: [0.0, 0.5]
        initState: [10.0, 0.0]
        interval: 10
        name: Mav-v0
        obsNoise: [0.0]
        render: False
        rewardMods: [1.0, 15.0, 1.0, 1.0]
        stateObs: divergence
        steps: 200
network:
    desc: "hiddenSize: size of hidden layer, memorySize: size of memory for experience learning"
    value:
        hiddenSize: 128
        memorySize: 10000
